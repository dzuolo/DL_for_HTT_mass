#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from optparse import OptionParser
usage = "usage: %prog [options] <input hdf5> <output>"
parser = OptionParser(usage=usage)
parser.add_option("-m", "--minmass", dest = "min_mass",
                  default = 0.090)
parser.add_option("-M", "--maxmass", dest = "max_mass",
                  default = 0.800)
parser.add_option("-T", "--TeV", dest = "TeV_switch",
                  default = False, action = 'store_true')
parser.add_option("-t", "--train_frac", dest = "train_frac",
                  default = "0.7")
parser.add_option("-v", "--valid_frac", dest = "valid_frac",
                  default = "0.2")
parser.add_option("-r", "--random_seed", dest = "random_seed",
                  default = "2020")
parser.add_option("-F", "--Flat", dest = "Flat",
                  default = False, action = 'store_true')

(options,args) = parser.parse_args()

options.min_mass = float(options.min_mass)
options.max_mass = float(options.max_mass)
options.train_frac = float(options.train_frac)
options.valid_frac = float(options.valid_frac)
options.random_seed = int(options.random_seed)

input_file = args[0]
output_file = args[1]

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd

# Load data
df = pd.read_hdf(input_file)

# GeV to TeV
GeV_vars = ["MET_cov", "_pt_", "_mass_", "mT", "_E_"]
if options.TeV_switch:
    for k in df.keys():
        if any([GeV_var in k for GeV_var in GeV_vars]):
            df[k] *= 1./1000

# make transverse masses
pt_str = "pt"
phi_str = "phi"    
for ana in ["reco", "gen"]:
    df["mT1_{ana}".format(ana=ana)] = (2*df["tau1_{pt}_{ana}".format(pt=pt_str, ana=ana)]*df["MET_{pt}_{ana}".format(pt=pt_str, ana=ana)]*(1-np.cos(df["tau1_{phi}_{ana}".format(phi=phi_str, ana=ana)]-df["MET_{phi}_{ana}".format(phi=phi_str, ana=ana)])))**.5
    df["mT2_{ana}".format(ana=ana)] = (2*df["tau2_{pt}_{ana}".format(pt=pt_str, ana=ana)]*df["MET_{pt}_{ana}".format(pt=pt_str, ana=ana)]*(1-np.cos(df["tau2_{phi}_{ana}".format(phi=phi_str, ana=ana)]-df["MET_{phi}_{ana}".format(phi=phi_str, ana=ana)])))**.5
    df["mTtt_{ana}".format(ana=ana)] = (2*df["tau1_{pt}_{ana}".format(pt=pt_str, ana=ana)]*df["tau2_{pt}_{ana}".format(pt=pt_str, ana=ana)]*(1-np.cos(df["tau1_{phi}_{ana}".format(phi=phi_str, ana=ana)]-df["tau2_{phi}_{ana}".format(phi=phi_str, ana=ana)])))**.5
    df["mTtot_{ana}".format(ana=ana)] = (df["mT1_{ana}".format(ana=ana)]**2+df["mT2_{ana}".format(ana=ana)]**2+df["mTtt_{ana}".format(ana=ana)]**2)**.5

# define target and input variables
target = "Higgs_mass_gen"

# look for variables distributions
df.hist(figsize = (24,20), bins = 500, log=True)
plt.plot()
plt.savefig("variables.png")
plt.close('all')
C_mat = df.corr()
fig = plt.figure(figsize = (15,15))
mask = np.zeros_like(C_mat)
mask[np.triu_indices_from(mask)] = True
import seaborn as sb
sb.heatmap(C_mat, vmax = 1, square = True, center=0, cmap='coolwarm', mask=mask)
fig.savefig("correlations.png")
plt.close('all')

def train_valid_test_split(df, train_size=.6, valid_size=.2, test_size=.2, seed=None):
    np.random.seed(seed)
    total_size = train_size + valid_size + test_size
    train_percent = train_size / total_size
    valid_percent = valid_size / total_size
    test_percent = test_size / total_size
    perm = np.random.permutation(df.index)
    m = len(df)
    train_end = int(train_percent * m)
    valid_end = int(valid_percent * m) + train_end
    train = perm[:train_end]
    valid = perm[train_end:valid_end]
    test = perm[valid_end:]
    return train, valid, test

# Split index ranges into training and testing parts with shuffle
train_size = options.train_frac
valid_size = options.valid_frac
test_size = 1 - (options.train_frac + options.valid_frac)
test_size = max([0, test_size])

np_train, np_valid, np_test = train_valid_test_split(
    df,
    train_size = train_size,
    valid_size = valid_size,
    test_size = test_size,
    seed = options.random_seed)

df["is_train"] = np.zeros(len(df[target]))
df["is_valid"] = np.zeros(len(df[target]))
df["is_test"] = np.zeros(len(df[target]))
df.loc[np_train, ["is_train"]] = 1
df.loc[np_valid, ["is_valid"]] = 1
df.loc[np_test, ["is_test"]] = 1

# ensure flat target distribution
# compute bin content to use
df["was_train"] = np.zeros(len(df[target]))
df["was_valid"] = np.zeros(len(df[target]))
df["was_test"] = np.zeros(len(df[target]))
if options.Flat:
    flat_step = 5e-3 # bin width in TeV for which content will be taken as constant
    flat_mass = min_mass+2e-3
    min_bin_content = {
        "train" : len(df.loc[df["is_train"] == 1, [target]]),
        "valid" : len(df.loc[df["is_valid"] == 1, [target]]),
        "test"  : len(df.loc[df["is_test"] == 1, [target]]),
    }

    flat_mass -= flat_step
    while flat_mass < max_mass-2e-3:
        flat_mass += flat_step
        for t in min_bin_content.keys():
            bin_content = len(df.loc[(df["is_{}".format(t)] == 1) & (df[target] >= flat_mass-flat_step/2) & (df[target] <= flat_mass+flat_step/2), [target]])
            if min_bin_content[t] > bin_content and bin_content != 0:
                min_bin_content[t] = bin_content

    # apply bin content
    flat_mass = min_mass+2e-3
    flat_mass -= flat_step
    while flat_mass < max_mass-2e-3:
        flat_mass += flat_step
        for t in min_bin_content.keys():
            bin_total = len(df.loc[(df["is_{}".format(t)] == 1) & (df[target] >= flat_mass-flat_step/2) & (df[target] <= flat_mass+flat_step/2), ["is_{}".format(t)]])
            df.loc[(df["is_{}".format(t)] == 1) & (df[target] >= flat_mass-flat_step/2) & (df[target] <= flat_mass+flat_step/2), ["was_{}".format(t)]] = np.concatenate([np.zeros(min_bin_content[t]), np.ones(bin_total-min_bin_content[t])])
            df.loc[(df["is_{}".format(t)] == 1) & (df[target] >= flat_mass-flat_step/2) & (df[target] <= flat_mass+flat_step/2), ["is_{}".format(t)]] = np.concatenate([np.ones(min_bin_content[t]), np.zeros(bin_total-min_bin_content[t])])

    # control variables
    df.loc[(df["is_test"] == 1) | (df["is_valid"] == 1) | (df["is_train"] == 1)].loc[(df[target] >= min_mass) & (df[target] <= max_mass)].drop(columns=[k for k in df.keys() if any(t in k for t in ["_test", "_valid", "_train"])]).hist(figsize = (24,20), bins = 500, log=True)
    plt.plot()
    plt.savefig("variables_flat_target.png")
    plt.close('all')
    C_mat = df.loc[(df["is_test"] == 1) | (df["is_valid"] == 1) | (df["is_train"] == 1)].loc[(df[target] >= min_mass) & (df[target] <= max_mass)].drop(columns=[k for k in df.keys() if any(t in k for t in ["_test", "_valid", "_train"])]).corr()
    fig = plt.figure(figsize = (15,15))
    mask = np.zeros_like(C_mat)
    mask[np.triu_indices_from(mask)] = True
    import seaborn as sb
    sb.heatmap(C_mat, vmax = 1, square = True, center=0, cmap='coolwarm', mask=mask)
    fig.savefig("correlations_flat_target.png")
    plt.close('all')

for k in df:
    if any([s in k for s in ["is_", "was_"]]):
        df[k] = df[k].astype('bool')
    elif k == 'Event_gen':
        df[k] = df[k].astype('int32')
    elif any([s in k for s in ["_Charge_", "_PID_", "_charge_", "_pdgId_"]]):
        df[k] = df[k].astype('int8')
    elif any([s in k for s in ["_eta_", "_phi_", "_pt_", "_mass_", "_btagDeepB_", "mT"]]):
        df[k] = df[k].astype('float16')
    elif df[k].dtype == 'float64':
        df[k] = df[k].astype('float32')
    elif df[k].dtype == 'int64':
        df[k] = df[k].astype('int16')

df.to_hdf("{}.h5".format(output_file), key='df')
