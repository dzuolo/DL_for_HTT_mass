#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os

from optparse import OptionParser
usage = "usage: %prog [options] <perfs>"
parser = OptionParser(usage=usage)
parser.add_option("-t", "--top", dest = "top", type=float, default=10)
parser.add_option("-o", "--output", dest = "output",
                  default = None)

(options,args) = parser.parse_args()

models_perfs = {}
classements = {}

for model_perf in args:
    if not "-SGD-" in model_perf or "ADAM_glorot_uniform" in model_perf:
        models_perfs[model_perf] = {}
        for region in ["low", "medium", "high", "full"]:
            for perf in ["median_diff", "CL68_width", "CL95_width", "CL68_calibr_width", "CL95_calibr_width"]:
                key="_".join([region, perf])
                if "CL95" in key:
                    continue
                if key not in classements:
                    classements[key] = []
                models_perfs[model_perf][key] = float(os.popen('grep {} {}'.format(key, model_perf)).readlines()[0][:-1].split(" ")[1])

for key in classements:
    classements[key] = sorted(
        [k for k in models_perfs.keys()],
        key = lambda k : models_perfs[k][key],
        reverse = False,
        )

print("Classements faits. Filtrage en cours ...")

N_models = len(args)

# Keep all models in top X% for each classes
Kept = set()
for key in classements:
    for model in classements[key][:int(len(classements[key])*options.top/100)+1]:
        Kept.add(model)

print("Top {}% filtering:\n\t{}/{} left ({}%)".format(options.top, len(Kept), N_models, int(100*len(Kept)/N_models)))

# Remove large dispersion at low mass
for model in [models for models in Kept]:
    if classements["low_CL68_calibr_width"].index(model)+1 > N_models*options.top/100 and classements["low_median_diff"].index(model)+1 > N_models*options.top/100:
        Kept.remove(model)

print("Large tails at low mass filtering:\n\t{}/{} left ({}%)".format(len(Kept), N_models, int(100*len(Kept)/N_models)))

# Remove biaised models
for model in [models for models in Kept]:
    if classements["medium_median_diff"].index(model)+1 > N_models*options.top/100:
        Kept.remove(model)

print("Biaised models filtering:\n\t{}/{} left ({}%)".format(len(Kept), N_models, int(100*len(Kept)/N_models)))

# Remove any model being in revsersed top
for model in [models for models in Kept]:
    if any([classements[key].index(model)+1 > N_models*(1-options.top/100) for key in classements]):
        Kept.remove(model)

print("Bottom filtering:\n\t{}/{} left ({}%)".format(len(Kept), N_models, int(100*len(Kept)/N_models)))
    
# restrict to 10 models
max_cuts = {}
for key in classements:
    max_cuts[key] = 0
for model in Kept:
    for key in classements:
        if models_perfs[model][key] > max_cuts[key]:
            max_cuts[key] = models_perfs[model][key]

while len(Kept) > 10:
    for key in max_cuts:
        max_cuts[key] *= 0.99
    for model in [models for models in Kept]:
        if any(
                [
                    models_perfs[model][key] > max_cuts[key] for key in max_cuts
                    ]
                ):
            Kept.remove(model)
    print(len(Kept))
    
for model in Kept:
    print(model)
    for key in classements:
        print("    {} : {}/{} ({}%)".format(key, classements[key].index(model)+1, N_models, int((classements[key].index(model)+1)/N_models*100)))

output_file = "~/ML/Best_models_from_ml_classer{}.out".format("" if options.output == None else "-"+options.output)
os.system("rm -rf {}".format(output_file))
Kept = [model for model in Kept]
Kept.sort()
for model in Kept:
    os.system(
        'echo "{}" >> {}'.format(
            model.replace("perfs", "json"),
            output_file
        )
)
